{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'diabetes_data_preprocessed_dropped_duplicates_1.csv'\n",
    "df = pd.read_csv(file, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_dict = {'Asian':0, 'Caucasian':1,'AfricanAmerican':2,'Hispanic':3,'Other':4,'?':5}\n",
    "df[\"race\"].replace(race_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =df.drop([df.columns[0],df.columns[1],df.columns[2]],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_1 = ['race',\n",
    " 'gender',\n",
    " 'age',\n",
    " 'admission_type_id',\n",
    " 'discharge_disposition_id',\n",
    " 'admission_source_id',\n",
    " 'time_in_hospital',\n",
    " 'num_lab_procedures',\n",
    " 'num_procedures',\n",
    " 'num_medications',\n",
    " 'number_outpatient',\n",
    " 'number_emergency',\n",
    " 'number_inpatient',\n",
    " 'diag_1',\n",
    " 'diag_2',\n",
    " 'diag_3',\n",
    " 'number_diagnoses',\n",
    " 'max_glu_serum',\n",
    " 'A1Cresult',\n",
    " 'metformin',\n",
    " 'repaglinide',\n",
    " 'nateglinide',\n",
    " 'chlorpropamide',\n",
    " 'glimepiride',\n",
    " 'acetohexamide',\n",
    " 'glipizide',\n",
    " 'glyburide',\n",
    " 'tolbutamide',\n",
    " 'pioglitazone',\n",
    " 'rosiglitazone',\n",
    " 'acarbose',\n",
    " 'miglitol',\n",
    " 'troglitazone',\n",
    " 'tolazamide',\n",
    " 'insulin',\n",
    " 'glyburide-metformin',\n",
    " 'glipizide-metformin',\n",
    " 'glimepiride-pioglitazone',\n",
    " 'metformin-rosiglitazone',\n",
    " 'metformin-pioglitazone',\n",
    " 'change',\n",
    " 'diabetesMed',\n",
    " 'service_utilization',\n",
    " 'numchange',\n",
    " 'nummed',\n",
    " 'level1_diag1',\n",
    " 'number_emergency_log',\n",
    " 'number_emergency_log1p',\n",
    " 'number_inpatient_log',\n",
    " 'number_inpatient_log1p',\n",
    " 'number_outpatient_log',\n",
    " 'number_outpatient_log1p',\n",
    " 'service_utilization_log',\n",
    " 'service_utilization_log1p',\n",
    " 'readmitted_log']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change feature set\n",
    "feature_set_2 = ['race','age', 'time_in_hospital', 'num_lab_procedures', 'num_procedures','change', 'service_utilization_log1p', 'number_diagnoses','num_medications','number_outpatient','number_emergency','number_inpatient']\n",
    "train_input = df1[feature_set_2]\n",
    "train_output = df1['readmitted']\n",
    "from sklearn.model_selection import train_test_split\n",
    "# shuffles, %80 training, %20 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### Logistic regression ###\n",
    "###########################\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input, \\\n",
    "                                                  train_output, \\\n",
    "                                                  test_size=0.20, \\\n",
    "                                                  random_state=0)\n",
    "logit = sm.Logit(Y_train, X_train)\n",
    "result = logit.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input, train_output, test_size=0.20, random_state=0)\n",
    "logreg = LogisticRegression(fit_intercept=True, penalty='l1')\n",
    "print(\"Cross Validation Score: {:.2%}\".format(np.mean(cross_val_score(logreg, X_train, Y_train, cv=10))))\n",
    "logreg.fit(X_train, Y_train)\n",
    "print(\"Dev Set score: {:.2%}\".format(logreg.score(X_dev, Y_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "Y_dev_predict = logreg.predict(X_dev)\n",
    "pd.crosstab(pd.Series(Y_dev, name = 'Actual'), pd.Series(Y_dev_predict, name = 'Predict'), margins = True)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(Y_dev, Y_dev_predict)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(Y_dev, Y_dev_predict)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(Y_dev, Y_dev_predict)))\n",
    "print(\"AUC is {0:.2f}\".format(roc_auc_score(Y_dev, Y_dev_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "##### Decision Trees #####\n",
    "##########################\n",
    "\n",
    "# Data balancing applied using SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(train_output)))\n",
    "\n",
    "smt = SMOTE(random_state=20)\n",
    "train_input_new, train_output_new = smt.fit_sample(train_input, train_output)\n",
    "print('New dataset shape {}'.format(Counter(train_output_new)))\n",
    "train_input_new = pd.DataFrame(train_input_new, columns = list(train_input.columns))\n",
    "X_train, X_dev, Y_train, Y_dev = train_test_split(train_input_new, train_output_new, test_size=0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Can change with gini\n",
    "# grid search?\n",
    "dte = DecisionTreeClassifier(max_depth=28, criterion = \"entropy\", min_samples_split=10)\n",
    "print(\"Cross Validation score: {:.2%}\".format(np.mean(cross_val_score(dte, X_train, Y_train, cv=10))))\n",
    "dte.fit(X_train, Y_train)\n",
    "print(\"Dev Set score: {:.2%}\".format(dte.score(X_dev, Y_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_dev_predict = dte.predict(X_dev)\n",
    "pd.crosstab(pd.Series(Y_dev, name = 'Actual'), pd.Series(Y_dev_predict, name = 'Predict'), margins = True)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "print(\"Accuracy is {0:.2f}\".format(accuracy_score(Y_dev, Y_dev_predict)))\n",
    "print(\"Precision is {0:.2f}\".format(precision_score(Y_dev, Y_dev_predict)))\n",
    "print(\"Recall is {0:.2f}\".format(recall_score(Y_dev, Y_dev_predict)))\n",
    "print(\"AUC is {0:.2f}\".format(roc_auc_score(Y_dev, Y_dev_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "from sklearn import tree\n",
    "\n",
    "dot_dt_q2 = tree.export_graphviz(dte, out_file=\"dt_q2.dot\", feature_names=X_train.columns, max_depth=2, class_names=[\"No\",\"Readm\"], filled=True, rounded=True, special_characters=True)\n",
    "graph_dt_q2 = pydotplus.graph_from_dot_file('dt_q2.dot')\n",
    "Image(graph_dt_q2.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most important features\n",
    "# Shot top most features based on importance\n",
    "feature_names = X_train.columns\n",
    "feature_imports = dte.feature_importances_\n",
    "most_imp_features = pd.DataFrame([f for f in zip(feature_names,feature_imports)], columns=[\"Feature\", \"Importance\"]).nlargest(10, \"Importance\")\n",
    "most_imp_features.sort_values(by=\"Importance\", inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(range(len(most_imp_features)), most_imp_features.Importance, align='center', alpha=0.8)\n",
    "plt.yticks(range(len(most_imp_features)), most_imp_features.Feature, fontsize=14)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Most important features - Decision Tree (entropy) (Question 2 - complex model)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
